\chapter{State of the Art}\label{chapter:c2}
\markboth{Chapter~\ref{chapter:c2}. State of the Art}{}
In this chapter, it will be introduced the state-of-the-art 
related to the specification, formalization and verfication
of stateful web services and their composition as well as the use of formal methods in this topic. The aim of this chapter is to provide the reader
with the basic notions about formal methods and stateful web service compositions in order to help he/she in the understanding
of the Thesis. To begin with, a brief introduction of formal methods 
and why they are needed is presented. Second, a survey about the diffent technologies used to model web services
and the different approaches to compose them are introduced and,
next, the different mechanisms available to improve
these web services with distributed resources. 
Finally, the different formal models used here are defined. 
On the other hand, we introduce workflow nets
and why they are useful to model business processess. 
Some informal definition about the properties can be studied with this formal model is also provided. 

\section{Motivation}

Throughout the history of computing , engineers and researchers have used different formal methods to improve the quality of hardware and software. These systems with continuous technological progress in integration techniques and programming methodologies inevitably grow in scale and complexity. Because of this complexity, the probability of error is higher and, in addition, some of these errors can cause incalculable economic losses, time or even the loss of human lives. Therefore, the main aim of designers should be to provide developers with the required tools to build systems with a negligible error rate and with the lowest cost. However, this task is far from trivial since one needs to ensure the correctness of the specifications and needs to provide techniques that ease error detection and the verification of the developed models without consuming so much time of the development process. One of the ways that engineers have been used to achieve this goal is the use of formal techniques to ensure the correctness of the development process as well as the product under construction. These formal methods can be defined as the set of procedures and tools based on mathematical languages that virtually ensure the correctness of a system \cite{Clarke96} since they increase the level of knowledge that the participants have about the system, revealing inconsistencies and ambiguities that could not be detected using other techniques, i.e., the use of formal methods provides a greater degree of refinement of the model than other methods.


\begin{figure}
\begin{center}
  \includegraphics[scale=0.5, width =\columnwidth]{Figures/usos}
\end{center}
  \caption{Example of systems where formal methods are (can be) used .}
  \label{fig:uso}
\end{figure}

In the past, the use of formal techniques in practice seemed to be utopian and unrealizable. 
Among other causes, the notations used to require a high mathematical background in
mathematics and, therefore, they were too complicated for the uninitiated in the topic. 
The techniques did not allow the system to be scalable and the existing tools were
too difficult to use or understand or even there were no tools for a particular 
technique or formalism. In addition, case studies were not convincing enough and, 
therefore, developers could not appreciate the usefulness of formalization. 
However, in the early 90s, it started to glimpse a new way in this area. 
For the specification of software, the industry began to use the language Z \cite{Abrial80} 
in order to obtain rigorous specifications. For hardware verification, major 
companies such as Intel and AMD started to use formal techniques such as \emph{model checking} 
or \emph{theorem proving} to supplement tests on simulators. This led to the description of larger case studies,
which was benefitial for the advance of this area since other developers started to consider the possibility of 
introducing the use of formal techniques into their development processes.
In Figure \ref{fig:uso}, one can observe different systems in which these techniques are currently
used to ensure proper operation. For instance, big companies (e.g Boeing and Airbus)
use formal languages to specify the requirements of the equipment as well as they use 
formal methods to verify the most critical systems in the aircrafts. Moreover, automotive
companies verify the most critical systems ( e.g. brake or airbag systems) using \emph{model checking}. 

The main advantages of using formal methods are:

\begin{itemize}
\item The use of mathematics as a base gives this approach a certain rigour.
\item Identify ambiguity and inconsistencies.
\item Facilitates the construction of consistent and \emph{deadlock-free} systems.
\item Provides customer confidence in the system.
\item There are many tools that support the existing techniques.
\item Find bugs early should save money.
\end{itemize} 

The main disadvantages (or beliefs) that slow the progress of this area are:

\begin{itemize}
\item It is believed that the use of formal methods slows the development process.
\item Many developers think it is difficult to work with formal specifications.
\item It does not guarantee the correctness of the implemented code (only the model
it is based).
\item Increasing system complexity causes an exponential increase
the complexity of the verification.
\end {itemize}

As commented previously, companies can use formal methods along the entire
development lifecycle of a system, both hardware and software. 
Here, we will focus on software since this Thesis studies different standards for building software components. 
Next, we describe the different phases in which designers can apply any formal technique. 

One of the most important part in the development of a system is the requirements specification. 
A specification can be seen as a technical document where the features and services needed 
to build a product are stated. Nevertheless, it can also include information on 
subsequent steps such as verification, validation, testing, etc. Therefore, 
this should be the first part in which the participants should apply formal methods, taking the 
required time to correctly specify the system since a neat and correct specification will influence the 
rest of the proccess.
Anyway, make a proper specification does not guarantee the absence of errors because the 
presence of faults is an intrinsic characteristic of the systems. In this sense, 
the simple act of writing the document helps engineers to find errors in the early stages 
of the development process, helping the company to save  money and time. 
In Figure \ref{fig:coste}, one can observe what is the effect (in money) of finding a bug
in the different phases. As can be observed, the cost of fixing a bug increases as 
we advance in the lifecycle and, therefore, it is recommended to find these bugs as soon as possible. 
In this Thesis, we propose a formal language and its visual model to specify web service compositions 
with distributed resources, but this will be presented in Chapter \ref{chapter:c3}.

\begin{figure}
\begin{center}
  \includegraphics[scale=0.5, width =\columnwidth]{Figures/coste}
\end{center}
  \caption{Cost evolution of fixing a bug.}
  \label{fig:coste}
\end{figure}

In the classic life cycle, the verification and validation phases are performed after the implementation phase, 
but as we have seen in Figure \ref{fig:coste}, it is advisable to detect these errors as soon as possible. 
As expected, it is practically impossible to verify completely all the behaviour of a complex 
system so that the goal of researchers in this area is to check whether certain properties hold in the model. 
The properties of interest will be related to the classical problems of concurrency (\emph{deadlock, mutual exclusion,\ldots}) 
and some aspects directly related to the system itself such as check 
the adherence of it to certain time constraints. For example, in a banking system, 
it is mandatory to ensure that transactions meet the stipulated time for completion 
because if you exceed these restrictions some security issues could come out.

In this sense, one can follow two different ways to perform 
the verification of a system: \emph{Human-directed proof or Automated proof}.
The first one is used when you want to strengthen the knowledge of the system 
rather than completely ensure the correctness of it, and, therefore, it is a person who check the properties manually. 
This variant improves the knowledge of the system, but it is time-consuming and 
error-prone due to the entire process is conducted for a human being. 
In the second approach (\emph{automated proof}) there are also two variants: \emph{automated theorem proving and model checking}. 
The \emph{automated theorem proving } is conducted by a program that tries 
to produce a formal proof of a system from scratch, giving a description of it, 
a set of logical axioms and a set of inference rules. On the other hand, model checking \cite{Clarke99} 
is a technique for verifying finite state concurrent systems. It has a number of advantages 
over traditional approaches that are based on simulation, testing, and deductive reasoning. 
In particular, model checking is normally automatic and usually quite fast. Also, if the design contains an error, 
model checking will produce a counterexample that can be used to pinpoint the source of the error. 
Here, the specification can be expressed in propositional temporal logic propositional 
normally LTL \cite{Pnueli77} or CTL \cite{Henzinger94} or some of its variants, 
and the system is represented as a graph of transitions between states. 
The main challenge in model checking is dealing with the state space explosion problem. 
When dealing with web systems, this problem occurs in systems with many components that can interact with 
each other or systems with data structures that have many different values. 
In such cases the number of global states can be enormous. 
Researchers have made considerable progress on this problem over the last ten years. 
% Typically , the client only available to the engineer high-level representation of the system (usually in natural language ) and the specification of the same , also in natural language. So any \ emph { model checker } ( Spin \cite{Holz04} , UPPAAL \cite {Larsen97}, etc.) Exits with an affirmative answer if the proposed design meets the specification or provides a counterexample to locate where it has the error.

 
\section{Web Services modelling}

Although the Web was initially intended for the exclusive use of human beings, 
many experts believe that it needs to evolve (probably through modular design 
and construction services) to better support for the automation of many tasks. 
The concept of \emph{service} provides a higher level of abstraction to organize 
large-scale applications and build more open environments, helping to develop 
applications with improved productivity and quality with respect to other approaches. 
As services are only a mean for building distributed applications, 
it is required to evaluate the different existing approaches in this area. 
Figure \ref{arch} shows an example of service-based architecture, 
where there are three main parts: a consumer, a provider (the servers) and a set of records, 
where the services are stored. The role of the providers is to publish and/or advertise the 
services offered in the records, where consumers can find and invoke them. 
Current standards that support interactions between web services provide a 
solid foundation for service-oriented architecture. 
The web architecture is a framework that can be reinforced with more 
powerful representations and techniques inherited from other approaches.

\begin{figure}
\begin{center}
  \includegraphics[width =\columnwidth]{Figures/clientserver.eps}
\end{center}
  \caption{Client-server web architecture}
  \label{arch}
\end{figure}

In this way, Service-Oriented Computing (SOC) paradigm promotes the use of services 
for the development of massively distributed applications, trying to achieve the creation of fast, 
low-cost, flexible and scalable applications \cite{Papazoglou2007}. 
Services are the main building block of this paradigm, being these services self-describing and platform-independent. 
Thanks to the use of standards for the description, publication, discovery and invocation, 
the services can be integrated without taking care of the low-level implementation 
details of each service. The aim of SOC is to make possible 
the creation of dynamic business processes and agile applications 
by providing an easy way to assemble application components into a loosely coupled network of services.

To reach the goals of SOC, a Service-Oriented Architecture (SOA) is defined. 
SOA is a software architecture based on the utilization of services, 
being these services provided to the user of the application or to other services in the network. 
This is possible by the use of service interfaces that can be published and discovered. 
SOA is based on a model of roles where every service can play multiple roles. 
For example, a service can offer certain functionality to a user and, at the same time, 
being the consumer of the functionality provided by some other services. 
Such model reduces the complexity of applications and increases their flexibility. 
Although at the beginning of SOA there were several architectures aspiring 
to become SOA standards \cite{Karp2000,Sun1999}, the most successful one was the architecture based on Web Services.

W3C defines a Web Service (WS) in the following way:

\begin{quotation}
	``A Web Service is a software system designed to support interoperable machine-to-machine interaction over a network. It has
an interface described in a machine-processable format (specifically WSDL). Other systems interact with the Web Service in a manner prescribed by its description using SOAP-messages, typically conveyed using HTTP with an XML serialization in conjunction with other Web-related standards.''
\end{quotation}

We can see in this definition that there are two basic standards 
related to Web Services: Web Service Description Language (WSDL) for the definition 
of the service functionality and its properties \cite{W3C2001}, 
and Simple Object Access Protocol (SOAP) for the exchange of 
XML messages between services \cite{W3C2007}. 
There is also an additional standard called Universal Description, Discovery and Integration (UDDI) 
used to create Web Service directories and to search for services 
in the network \cite{OASIS2004}, but this is a bit out of date. The use of these standard protocols is 
the key point to improve the integration between different parties in a web service architecture.

In Figure \ref{Figure1} a possible representation of the web service architecture stack is shown. 
One can see that the three standards described above are only a small part of the stack. 
One also need protocols to define security aspects (ensuring that exchanges of information 
are not modified or forgotten in a verifiable manner and that parties can be authenticated), 
to provide reliable messaging for the exchange of information between parties, 
to specify the collaboration between services when we compose them, 
to individually describe the behaviour of each service in a business process, etc. 
The problem is that whereas the standards for basic services (WSDL and SOAP) 
are widely adopted for their respective purposes, the situation is not very 
clear when we talk about composing services, 
having multiple protocols aspiring to become a standard in this layer.

\begin{figure}[h]
\begin{center}
\psfig{file=Figures/ws-stack.eps,scale=.55}
\end{center}
\caption{Web Service architecture stack.}
\label{Figure1}
\end{figure}

Two different approaches can be followed when we designing web service compositions. 
They are called \textit{orchestration} and \textit{choreography}. 
The former describes the individual business process followed by 
each one of the participants in the composition, 
while the latter describes the composition from a global viewpoint, 
defining the interactions (exchange of messages) happening between the parties, that is, 
how they collaborate in the composition. However, the ideal solution would 
be fusing both approaches in a single language and environment \cite{Papazoglou2007}.

Anyway, the languages we can use in both cases should accomplish some common goals: 
(i) the capacity of modelling service interactions, including control flow and data constraints, 
(ii) the possibility of specifying exceptional behaviour, 
indicating which errors can happen in the execution of the composition 
and the way of handling these errors, and (iii) the ability to model web service compositions at a high level, 
without taking care of the implementation details of each one of the services.

Regarding the choreography approach, there are several languages that 
have been designed for that purpose. One of the most popular languages 
is Web Services Choreography Description Language (WS-CDL), 
which specifies the common and complementary observable behaviour of 
all participants in a composition \cite{W3C2005}. 
It is based on XML and describes the peer-to-peer collaborations 
between the composite web services from a global point of view, that is, 
the exchange of messages to achieve a common business goal. 
The aim of this language is allowing the composition of any kind of web services, 
regardless of the platform hosting the service or the implementation language. 
Figure \ref{Figure2} is an example of how WS-CDL can be useful 
for the integration of different kinds of web services.

\begin{figure}[h]
\begin{center}
\psfig{file=Figures/WSCDL.eps,scale=.7}
\end{center}
\caption{Integration of Web Services using WS-CDL.}
\label{Figure2}
\end{figure}

A WS-CDL document defines a hierarchy of choreographies, where there is only one top-level choreography, marked explicitly as the \textit{root choreography}. The basic building block of a choreography is the \textit{interaction} element. It indicates information exchanges between participants, possibly including the synchronization of some information values. These interactions are performed when one participant sends a message to another participant in the choreography. When the message exchanges complete successfully, the interaction completes normally. 

We can distinguish two different kinds of \textit{complex activities} inside a choreography: the workunit element and the ordering structures. The \textit{workunit} element specifies a condition that must be fulfilled in order to perform some work and/or the repetition of some work. It completes successfully when the set of activities inside completes successfully. \textit{Ordering structures} are used to combine basic activities and other complex activities in a nested way, expressing the order in which actions are performed within the choreography. There are three ordering structures: The \textit{sequence} ordering structure expresses that the set of activities inside must be executed sequentially. The \textit{parallel} ordering structure indicates that the set of activities inside must be executed concurrently. It completes successfully when all the concurrent activities complete successfully. And the \textit{choice} ordering structure specifies that only one of multiple activities can be executed. If the choice have workunits inside, only the first one in lexical order with a ``true'' guard condition is selected. If there are other activities, there is no way to know which one is selected; it is considered as a non-observable decision.

Different types of exceptions are considered in WS-CDL. Exception workunits can be defined to handle all these exceptions. They may also be used as the mechanism to recover from the exceptions. At least one exception workunit must be defined. The guard of the workunit can be used to specify the particular type of exception we want to handle. Only one exception workunit can match each exception. If multiple exception workunits are defined, the order of evaluating them is based on the order in which the workunits have been defined. When the matching happens, the actions of the matched workunit are executed. If no matching happens and a default exception workunit exists, then the actions of this workunit are executed. Otherwise, the exception is raised in the parent choreography. WS-CDL also allows us to define finalization actions within a choreography that can confirm or cancel the effects of this choreography, so we can use this actions for compensation. 

\subsection {WS-BPEL}
Traditional methods for integration and business process automation 
typically involve embedded logic inside of applications designed 
to meet a specific business need such as ERP, supply chain, or CRM. 
The development, testing, and deployment efforts required 
to change these applications make integration and process changes both costly and complex.

To address these issues, proprietary products emerged 
to abstract integration and process automation into a new layer of software tools. 
These software products liberated integration and process tasks from 
the underlying business systems so they could be more effectively changed, managed, and optimized.

The Business Process Execution Language for Web Services (BPEL4WS) 
was first conceived in July, 2002 with the release of the BPEL4WS 
1.0 specification, a joint effort by IBM, Microsoft, and BEA. 
This document proposed an orchestration language inspired 
by previous variations, such as IBM?s Web Services Flow Language (WSFL) and Microsoft?s XLANG specification.

Joined by other contributors from SAP and Siebel Systems, version 1.1 
of the BPEL4WS specification was released less than a year later, in May of 2003. 
This version received more attention and vendor support, 
leading to a number of commercially available BPEL4WS-compliant 
orchestration engines. Just prior to this release, 
the BPEL4WS specification was submitted to an OASIS 
technical committee so that the specification could be developed into an official, open standard.

The OASIS WS-BPEL Technical Committee was active from April 2003 to May 2007. It was co-chaired by Diane Jordan of IBM and John Evdemon of Microsoft. The Committee's email archives remain publicly accessible.

In April 2007, WS-BPEL version 2.0 was approved as an OASIS Standard. More than 37 organizations collaborated to develop WS-BPEL, including representatives of Active Endpoints, Adobe Systems, BEA Systems, Booz Allen Hamilton, EDS, HP, Hitachi, IBM, IONA, Microsoft, NEC, Nortel, Oracle, Red Hat, Rogue Wave, SAP, Sun Microsystems, TIBCO, webMethods, and other members of OASIS.

In January 2008, OASIS issued a Call for Participation in the BPEL4People Technical Committee. The group works to define a WS-BPEL extension enabling the definition of human interactions ("human tasks") as part of a WS-BPEL process.

\begin{figure}[h]
\begin{center}
\psfig{file=Figures/bpelhistory.eps,scale=.7}
\end{center}
\caption{Integration of Web Services using WS-CDL.}
\label{Figure2}
\end{figure}

There were ten original design goals associated with BPEL:

    Define business processes that interact with external entities through web service operations defined using WSDL 1.1, and that manifest themselves as Web services defined using WSDL 1.1. The interactions are ?abstract? in the sense that the dependence is on portType definitions, not on port definitions.
    Define business processes using an XML-based language. Do not define a graphical representation of processes or provide any particular design methodology for processes.
    Define a set of Web service orchestration concepts that are meant to be used by both the external (abstract) and internal (executable) views of a business process. Such a business process defines the behavior of a single autonomous entity, typically operating in interaction with other similar peer entities. It is recognized that each usage pattern (i.e., abstract view and executable view) will require a few specialized extensions, but these extensions are to be kept to a minimum and tested against requirements such as import/export and conformance checking that link the two usage patterns.
    Provide both hierarchical and graph-like control regimes, and allow their use to be blended as seamlessly as possible. This should reduce the fragmentation of the process modeling space.
    Provide data manipulation functions for the simple manipulation of data needed to define process data and control flow.
    Support an identification mechanism for process instances that allows the definition of instance identifiers at the application message level. Instance identifiers should be defined by partners and may change.
    Support the implicit creation and termination of process instances as the basic lifecycle mechanism. Advanced lifecycle operations such as "suspend" and "resume" may be added in future releases for enhanced lifecycle management.
    Define a long-running transaction model that is based on proven techniques like compensation actions and scoping to support failure recovery for parts of long-running business processes.
    Use Web Services as the model for process decomposition and assembly.
    Build on Web services standards (approved and proposed) as much as possible in a composable and modular manner.

BPEL and Web services now provide a standardized integration interface 
and a standardized language for integration and process automation. 
BPEL, in effect, has the potential to commoditize the capabilities 
provided by proprietary EAI and BPM solutions. As often occurs in a 
commodity market, the resulting prices for products and services are certain to fall.
Developing the web services and exposing the functionalities is not sufficient. We also
need a way to compose these functionalities in the right order ? a way to define
business processes which will make use of the exposed functionalities. We would
obviously prefer a relatively simple and straightforward way to define such processes,
particularly because we know that business processes change often, therefore we
would like to modify them easily.
BPEL is thus comparable to general purpose programming language such as Java, but it
is not as powerful as Java. On the other hand it is simpler and better suited for business
process definition. Therefore BPEL is not a replacement but rather a supplement to
modern languages.
Choreography has not gained support from the
industry which would be comparable to BPEL.
This is where the BPEL (Business Process Execution Language for Web Services, also
WS-BPEL or BPEL4WS) becomes important. BPEL allows composition of web services
and is thus the top-down approach to SOA ? the process oriented approach to SOA.
Let us have a closer look at a typical BPEL process. First, the BPEL business process
receives a request. To fulfill it, the process then invokes the involved web services and
finally responds to the original caller. Because the BPEL process communicates with
other web services, it relies heavily on the WSDL description of the web services
invoked by the composite web service.

%The first version of BPEL has been developed in August 2002 by BEA, IBM, and
%Microsoft. Since then the majority of vendors have joined which has resulted in several
%modifications and improvements and adoption of version 1.1 in March 2003. In April
%2003, BPEL was submitted to OASIS (Organization for the Advancement of Structured
%Information Standards) for standardization purposes where the WSBPEL TC (Web
%Services Business Process Execution Language Technical Committee) has been formed
%since. This
%has led to even broader acceptance in industry.

The process-oriented approach to SOA requires a language for relatively simple
description of how web services should be composed into business processes. Of
course it would be great if such descriptions could also be executed, which would allow
us not only to define abstract process definitions, but to write exact executable
specifications of processes. BPEL is such a language. Actually it is the first language
which:

BPEL Language
1. Allows us to define abstract and executable processes
2. Is supported by the majority of companies
3. Software exists (from several vendors) on which such processes can be executed
(BPEL servers) and developed (BPEL designers).


The idea and motivation behind almost each new technology and platform for
enterprise application development is to provide an environment where better
business applications can be developed with less effort ?business applications which
should closely align to the business processes, which should not be too complex, and
which can be adapted to the changing nature of business processes without too much
effort.
Java has provided an excellent platform for developing such applications, but business
applications today cannot be isolated. Within companies, business applications have to
interoperate and integrate - so they have between companies. Integrating different
applications has always been a difficult task for various functional and technology
related reasons.
BPEL builds on top of XML and web services. It is an XML-based language which
supports the web services technology stack, including SOAP, WSDL, UDDI, WS-Reliable
Messaging, WS-Addressing, WS-Coordination and WS-Transaction. BPEL represents a
convergence of two early workflow languages, WSFL (Web Services Flow Language) and
XLANG. WSFL was designed by IBM and is based on the concept of directed graphs.
XLANG was designed by Microsoft and is a block-structured language. BPEL combines
both approaches and provides a rich vocabulary for description of business processes.
A BPEL process specifies the exact order in which participating web services should be
invoked. This can be done sequentially or in parallel. With BPEL, we can express
conditional behavior, for example, a web service invocation can depend on the value of
a previous invocation. We can also construct loops, declare variables, copy and assign
values, define fault handlers, and so on. By combining all these constructs, we can
define complex business processes in an algorithmic manner.
From the perspective of composing web services to execute business processes,
orchestration is the more flexible approach compared to choreography:
We know exactly who is responsible for the execution of the whole business
process.
We can incorporate web services, even those that are not aware that they are a
part of a business process.
We can also provide alternative scenarios when faults occur.
Developing the web services and exposing the functionalities is not sufficient. We also
need a way to compose these functionalities in the right order ? a way to define
business processes which will make use of the exposed functionalities. We would
obviously prefer a relatively simple and straightforward way to define such processes,
particularly because we know that business processes change often, therefore we
would like to modify them easily.
BPEL is thus comparable to general purpose programming language such as Java, but it
is not as powerful as Java. On the other hand it is simpler and better suited for business
process definition. Therefore BPEL is not a replacement but rather a supplement to
modern languages such as Java.
BPEL follows the orchestration paradigm. Choreography is covered by other standards,
such as WSCI (Web Services choreography Interface) and WS-CDL (Web Services
Choreography Description Language). Choreography has not gained support from the
industry which would be comparable to BPEL.
This is where the BPEL (Business Process Execution Language for Web Services, also
WS-BPEL or BPEL4WS) becomes important. BPEL allows composition of web services
and is thus the top-down approach to SOA ? the process oriented approach to SOA.
Let us have a closer look at a typical BPEL process. First, the BPEL business process
receives a request. To fulfill it, the process then invokes the involved web services and
finally responds to the original caller. Because the BPEL process communicates with
other web services, it relies heavily on the WSDL description of the web services
invoked by the composite web service.



Executable processesallow us to specify the exact details of business processes.
They can be executed by an orchestration engine. In most cases BPEL is used for
executable processes.
Abstract business protocols allow us to specify the public message exchange
between parties only. They do not include the internal details of process flows
and are not executable.
Choreography on the other hand does not rely on a central coordinator. Rather, each
web service involved in the choreography knows exactly when to execute its operations
and whom to interact with. Choreography is a collaborative effort focused on exchange
of messages. All participants of the choreography need to be aware of the business
process, operations to execute, messages to exchange, and the timing of message
exchanges.
The most recent answer to the integration challenge is the Service Oriented
Architecture (SOA) and the web services technologies. The bottom-up view of the SOA
sees different business applications exposing their functionalities through web services.
Thus we can now access different functionalities of different legacy and new developed
applications in a standard way (through web services). Such access to functionalities is
important because typical companies have a large number of existing applications
which have to be integrated.

 
WS-BPEL \cite{BPEL4WS}, for short BPEL, 
is an OASIS orchestration language for specifying actions within 
Web service business processes. BPEL is therefore an orchestration
language in the sense that it is used to define the composition
of services from a local viewpoint, describing the individual
behaviour of each participant. 
BPEL is designed to support the description of both behavioural service interfaces and executable
service-based processes \cite{OuyangVABDH07}. A behavioural interface (known as abstract process) is a specification of the
behaviour of a class of services, capturing constraints on the ordering of messages to be sent to and
received from a service. An executable process defines the execution
order of a set of activities (mostly communication activities), the partners involved in the process, the
messages exchanged between partners, and the events and exception handling specifying the behaviour
when specific events or faults occur.

Thus, a WS-BPEL abstract process is a partially specified process that is not intended to be executed
and it must be explicitly declared as ``abstract''. As its name indicates, 
an abstract process may hide some of the required 
operational details expressed by an executable artifact.
All the constructs of executables processes are made available to abstract processes
and, consequently, they share the same expressive power \cite{}. 
Although a particular Abstract Process definition might contain complete information that would
render it Executable, its Abstract status states that any concrete realizations of it are permitted to
perform additional processing steps that are not relevant to the audience to which it has been
given.

Abstract processes serve a descriptive role, with more than one use case. One such use case
might be to describe the observable behavior of some or all of the services offered by an
executable process. Another use case would be to define a process template that embodies
domain-specific best practices. Such a process template would capture essential process logic in
a manner compatible with a design-time representation, while excluding execution details to be
completed when mapping to an executable Process.


As mentioned above it is possible to use WS-BPEL to define an executable business process, that is, 
the language effectively defines a portable execution format for business processes that rely exclusively on
web Services and XML data. Moreover, such processes execute and interact with their
partners in a consistent way regardless of the supporting platform or programming model used
by the implementation of the hosting environment.
The continuity of the basic conceptual model between Abstract and Executable Processes in WS-
BPEL makes it possible to export and import the public aspects embodied in Abstract Processes
as process or role templates while maintaining the intent and structure of the observable behavior.
This applies even where private implementation aspects use platform dependent functionality.
This is a key feature for the use of WS-BPEL from the viewpoint of unlocking the potential of
web services because it allows the development of tools and other technologies that greatly
increase the level of automation and thereby lower the cost in establishing cross enterprise
automated business processes.

In detail, WS-BPEL defines a model and a grammar for describing the behavior of a business process
based on interactions between the process and its partners. The interaction with each partner
occurs through web service interfaces, and the structure of the relationship at the interface level
is encapsulated in what is called a partnerLink. The WS-BPEL process defines how multiple
service interactions with these partners are coordinated to achieve a business goal, as well as the
state and the logic necessary for this coordination. WS-BPEL also introduces systematic
mechanisms for dealing with business exceptions and processing faults. Moreover, WS-BPEL
introduces a mechanism to define how individual or composite activities within a unit of work
are to be compensated in cases where exceptions occur or a partner requests reversal.

A WS-BPEL process is a reusable definition that can be deployed in different ways and in
different scenarios, while maintaining a uniform application-level behavior across all of them.

BPEL processes use {\em variables} to temporarily store 
data. Variables are therefore declared on a process or on a scope 
within that process. I

BPEL activities 
can be \emph{basic} or \emph{structured}. 
\emph{Basic activities} are those which describe the elemental 
steps of the process behaviour, such as the assignment of
variables ({\em assign}), empty action ({\em empty}), 
time delay ({\em wait}), invoke a service ({\em invoke}) and receive
a message ({\em receive}), reply to a client ({\em reply}),
and throw an exception ({\em throw}). We also have an action to {\em terminate}
the process execution at any moment ({\em exit}).
For technical reasons we have also included a barred form of
{\em reply} action, which is used when a service invocation
expects a reply, in order to implement the synchronization with
the {\em reply} action from the server.  

\emph{Structured activities} encode control-flow logic in a nested
way. The considered structured activities are the following:
a {\em sequence} of activities, separated by a semicolon, 
the parallel composition, represented by two parallel bars ($\|$),
the conditional repetitive behaviour ({\em while}),
and a timed extension of the receive activity, which allows to
receive different types of messages with a time-out associated
({\em pick}).

\section{Cloud Computing/Grid Computing}
Gracias a la rápida evolución que ha tenido la sociedad, servicios básicos para el desarrollo de la vida cotidiana son comúnmente suministrados a los ciudadanos, de tal manera, que cualquier persona puede tener acceso inmediato a ellos de forma fácil. Hoy en día, estos servicios, conocidos en el mundo anglosajón como ``utility services'', engloban el suministro de agua, electricidad, gas y teléfono, pero en los últimos tiempos está cobrando fuerza una vieja idea que se intentó llevar a cabo sin éxito a finales de los años 60 y principios de los 70, el ``Utility Computing''. Este nuevo paradigma de computación es normalmente confundido con Cloud o Grid Computing, pero hay ciertos matices que los diferencian. ``Utility Computing'' se puede entender como el modelo de negocio que subyace en una infraestructura Cloud o Grid, es decir, puede ser entendido como el medio de cobro de servicios computacionales similar al que se hace con la electricidad, por lo que el usuario pagará sólo por su consumo, mientras que los costes asociados a la producción y distribución de potencia de cómputo serán sufragados por las compañías suministradoras. Así, las pequeñas y medianas empresas podrían competir en igualdad de condiciones con las grandes empresas, ya que no sería necesario hacer una gran inversión en datacenters para poder ofrecer un determinado servicio y se fomentaría la creación de empresas, ya que estos datacenters suponen una fuerte inversión inicial que muchos emprendedores no pueden acometer. Además, el usuario final de las aplicaciones, servicios o infraestructuras también se beneficiaría porque al reducir costes de producción se reduce el precio de los productos. Por seguir con el símil de la energía, podemos ver el cloud computing como una gran central generadora de energía que da suministro a millones de usuarios y que evita que dichos usuarios tengan que tener su propia central en casa para poder encender sus aparatos eléctricos, mientras que el ``utility computing'' es la forma de tarificar el gasto de los usuarios o, de una forma más abstracta, podemos verlo como el contador que muestra el consumo energético. Al igual que pasa con el software, los protocolos o cualquier paradigma relacionado con la informática, Cloud Computing debe atravesar una serie de etapas para poder comprobar si toda esta publicidad que le están dando las empresas sirve de veras para ahorrar costes y favorecer la competitividad o solo es más una forma de aumentar ingresos o, en el caso de la investigación, obtener nuevos fondos. En este sentido, algunos autores consideran que Cloud Computing no es mas que una nueva forma de nombrar lo que toda la vida se ha llamado Grid o Web Services y que realmente no supone ningún avance en el campo de la informática. Este artículo tratará de presentar más ampliamente la arquitectura y conceptos para comprender un sistema de computación basado en la nube y mostrará las diferencias entre dos enfoques clásicos de computación (Grid y Web Services) y Cloud. Finalmente, se propondrá una serie de ideas que pueden llegar a convertirse en trabajos de investigación en un futuro.         

\section{Introducción}

En 1943, el presidente de IBM, Thomas J. Watson, predijo:

\begin{center}
``I think there is a world market for about five computers''
\end{center}

Esta frase, tan comentada en el mundo de la informática en los últimos tiempos, ha pasado de ser una predicción con poco fundamento a ser una realidad en la actualidad.\\

Cloud Computing, el viejo sueño de ofrecer servicios de computación como utilidad, tiene el potencial de transformar gran parte de la industría informática, haciendo el software más atractivo al ofrecerlo como servicio y moldeando la forma en que se diseña y compra el hardware. Con este nuevo enfoque, cualquier emprendedor con buenas ideas para ofrecer servicios a través de Internet no necesitará realizar grandes inversiones en equipamiento para llevar a cabo su proyecto ni necesitará contratar inicialmente mucho personal que gestione y mantenga dicho equipamiento. Además, no tiene que realizar complicados estudios previos para calcular el número de usuarios potenciales y evitar, así, unos de los principales quebraderos de cabeza de los jefes de proyecto: el sobre-aprovisionamiento o el infra-aprovisionamiento. Estos dos conceptos junto con la elasticidad de recursos pueden ser considerados como claves en computación en la nube, ya que el objetivo de reducir costes es directamente proporcional a la correcta estimación de recursos en ``tiempo real'' y esta correcta estimación sólo se puede proporcionar si el sistema cumple la propiedad de elasticidad, es decir, que en un intervalo de tiempo relativamente corto aumentas y disminuyes los recursos dedicados a una tarea con un coste económico bajo. Este enfoque puede hacer que, a primera vista, no se perciba la posibilidad de utilizar métodos formales con este tipo de sistemas, puesto que normalmente se utilizan técnicas formales en el diseño de sistemas con tiempos de respuesta críticos como sistemas de navegación de un avión, transporte de materiales peligrosos, etc. De esta manera, se hace inviable el uso de la computación en la nube cuando se exijan tiempos de respuesta muy bajos, ya que, por ejemplo, un sistema de navegación de un avión no puede esperar varios minutos a que se le asignen nuevos recursos para tomar una decisión. Sin embargo, si que hay otro tipo de sistemas en los que los métodos formales y el cloud computing pueden converger, los sistemas de alta disponibilidad.\\

Así, utilizando técnicas formales se pueden diseñar este tipo de sistemas y verificar la ausencia de fallos en su construcción. Por ejemplo, una tienda de venta online podría pasar de tener cientos de usuarios simultáneamente a miles de ellos en periodos como las vacaciones de Navidad, de manera que necesitaría mucha mayor potencia de computación si quiere satisfacer a todos los clientes y no perder ingresos ni nuevos clientes por no poder atender esa demanda. Para satisfacer esta necesidad, haría un estudio preliminar de cuantas visitas como máximo puede tener en ese período y compraría los datacenters necesarios para no tener problemas de congestión, lo que supone una inversión grande en infraestructura por parte de la compañía, sin embargo, una vez acaba la campaña navideña la demanda de usuarios vuelve a ser de unos cientos y la empresa se encuentra con que tiene una potencia de cómputo que no va a necesitar y, por tanto, no está amortizando económicamente la inversión realizada. En este sentido, si la compañía en lugar de comprar los datacenters hubiese comprado capacidad de cómputo a un proveedor entonces habría amortizado en mayor medida el dinero invertido y no tendría máquinas en sus oficinas que ocupan bastante espacio y que tienen unos niveles de carga de trabajo muy bajos.  \\


Cloud Computing se refiere tanto a las aplicaciones que se ofrecen como servicios a través de Internet como al hardware y software que está presente en los datacenters que proveen dichos servicios. Estos servicios se han referido normalmente como Software as a Service (SaaS). El datacenter en sí es lo que se considera la nube (o cloud). Desde el punto de vista del hardware, hay tres aspectos novedosos en Cloud Computing: 

\begin{enumerate}
\item La ilusión de tener recursos ilimitados bajo demanda eliminando a los usuarios la necesidad de aprovisionarse antes de acometer una tarea.
\item La eliminación de la inversión inicial en equipamiento permitiendo a las compañías empezar con pocos recursos e ir aumentándolos cuando las necesidades aumenten.
\item La posibilidad de pagar por el uso de recursos de computación a corto plazo según se necesiten (por ejemplo, procesadores por hora o capacidad de almacenamiento de datos por día) y poder liberarlos cuando no sean necesarios. 
\end{enumerate}

Cloud Computing podría tener el mismo impacto en la producción de software que el que tuvieron las fundiciones de metal en la industría del hardware. En principio, las compañías fabricantes de hardware necesitaban tener sus propias instalaciones donde fabricar los componentes que componían sus productos, lo que les suponía un gran esfuerzo económico para construir y operar estas instalaciones y, por consiguiente, hacía que el precio de los equipos se doblase en cada nueva generación. Sin embargo, la aparición de compañías que fabricasen componentes favoreció que empresas más pequeñas pudiesen entrar en el mercado del hardware, copado hasta aquel entonces por Intel o Samsung, que eran las únicas que podían hacer frente a este gran esfuerzo económico. De manera similar, la computación en la nube podría jugar el papel que hicieron las fundiciones, favoreciendo la competencia y evitando monopolios de grandes empresas. \\

Debido a que muchas empresas usan servicios software como base para su modelo de negocio, se presentan, a continuación, los actores que formarán parte de este escenario. Los \emph{Services Providers}(SPs) hacen accesibles los servicios a los \emph{Service Users} por medio de interfaces que se comunican a través de Internet. Dado que uno de los objetivos de la nube es externalizar la provisión de servicios, se necesita la aparición de otro actor que ofrezca esta infraestructura como ``servicio'' llamado \emph{Infrastructure Provider}, migrando los recursos desde los SPs al IPs y, así, los SPs pueden ganar flexibilidad y reducir costes como se puede ver en la figura \ref{act}. 

\begin{figure}[bth]
  \center
    \includegraphics[scale=0.5]{Figures/actores}
  \caption{Actores en un sistema en la nube.}
  \label{act}
\end{figure}

\section{Comparación entre servicios web y Grid computing/Cloud computing}

Como es sabido, nuestro grupo de investigación ha centrado su investigación en el desarrollo de una metodología que permita construir y verificar sistemas con restricciones temporales mediante el uso de técnicas formales. En los últimos años, se ha aplicado esta metodología en el área de los servicios web, más concretamente, en que estos servicios cumplan la tarea que se les encomienda y que se coordinen automáticamente para conseguir llevar a cabo un trabajo más general. El problema que están teniendo los servicios web es que como tuvieron un gran auge hace pocos años, muchos grupos de investigación centraron sus estudios en este campo y, por tanto, hay muchos investigadores proponiendo nuevas aproximaciones y ésto ha llevado a que existen ciertas partes como BPEL o WS-CDL que están bastante estudiadas. De esta manera, esta surgiendo un sistema donde los métodos formales pueden jugar un papel muy importante y donde nuestro grupo puede beneficiarse de su amplia experiencia tanto en formalización como en servicios web, el cloud computing. Este nuevo paradigma, como se ha expuesto anteriormente, está viviendo su época de plenitud en este momento y grandes empresas como Google, IBM, Microsoft han decidido dar un paso al frente y apostar fuertemente por la computación en la nube. Además, muchos gobiernos están interesados en migrar sus servicios a la nube para abaratar costes y permitirles escalabilidad cuando les sea necesaria. Por ejemplo, hay que preguntarse si es necesario para la Agencia Tributaria tener grandes centros de datos cuando la demanda de servicios por parte de los ciudadanos sólo crece en la época de la declaración de la renta. Probablemente la respuesta sea afirmativa porque sí necesita almacenar todos esos datos y dar cierta confianza de que tus datos fiscales no van a caer en manos de gente con no muy buenas intenciones, pero toda la necesidad de cálculo si que se puede externalizar para ahorrar costes en equipamiento o incluso podrían crear una nube privada entre todos los organismos que colaboren con la agencia pública para compartir recursos e información. En este sentido, este tipo de sistemas donde la seguridad, privacidad y la disponibilidad son un requisito innegociable es donde podemos centrar parte de nuestras investigaciones e intentar mejorar alguno de los componentes de la arquitectura cloud expuesta en el apartado anterior. Por ejemplo, la mayoría de grupos de investigación desarrollan herramientas, pero la fase de pruebas o no existe o se le dedica poco tiempo. La semana pasada nos reunimos con uno de los grandes investigadores en el campo del Grid/Cloud Computing, Karim Djemame, y nos contó que el principal problema que tenía era ese que no sabían concretamente porque funcionaba bien su herramienta y que estaba bastante interesado en la verificación de su herramienta. \\


Por otro lado, a continuación se enumeran algunas diferencias entre servicios web y grid/cloud computing para ver donde es posible aplicar nuestra experiencia en este sistema. En primer lugar, podemos considerar que los servicios web son en sí software que se ofrece como servicio (SaaS), aunque existan ciertas diferencias entre ambos enfoques, por ejemplo, la estandarización. Por tanto, este software podría estar compuesto de un conjunto de servicios, probablemente comunicados a través de Internet, y que se coordinan para realizar una determinada tarea. Hasta el momento, nada nuevo, pero la principal diferencia reside en la virtualización, ya que los diferentes servicios que ofrece la nube se realizan en máquinas virtuales en lugar de directamente sobre un servidor como puede ser el caso del servicio web, de manera que la concurrencia en el sistema es mayor. \\

Otra diferencia es la persistencia de los datos. Si queremos coordinar varios servicios web para que realicen sumas la única posibilidad de que éstos puedan almacenar el resultado es guardándolo en la base de datos, sin embargo, existe una aproximación llamada WSRF (Web Services Resources Framework) que ha sido estandarizada y que resuelve este problema. En este framework cada servicio web lleva asociado un recurso o varios del sistema de manera que puedes interactuar con el servicio y decidir a que recurso acceder. La principal ventaja que tiene es que todos los servicios se definen con WSDL (Web Services Description Language) y que la comunicación, direccionamiento, etc. está estandarizado, de manera que la colaboración entre sistemas de este tipo es sencilla. Otra ventaja es que el usuario tiene la posibilidad de decidir con que recursos interactúa. Así, podríamos añadir una capa inferior en nuestra metodología que permitiese la definición de servicios web con recursos y una vez verificado que el sistema es correcto, desplegar estos servicios web en las máquinas físicas. Este enfoque encajaría perfectamente con nuestra investigación, ya que utiliza servicios web con recursos y estos recursos tienen restricciones temporales para evitar que un usuario abarque todo el sistema. \\   

También, podemos observar que cloud computing podría verse como una capa que se colocaría debajo de los servicios web, ya que se puede utilizar éstos para acceder a los recursos, pero hay que resaltar que la nube no es solo ofrecer software como servicio, sino que también hay infraestructura y plataforma como servicio, cosa que los servicios web no pueden abarcar. Es decir, una parte del cloud computing (SaaS) puede compararse directamente con los servicios web, pero las otras dos partes no tienen nada que ver, por lo que sería como comparar el protocolo TCP/IP con la arquitectura de un PC, aunque es necesario que ambas aproximaciones (servicios web y cloud computing) converjan para el crecimiento de ambos paradigmas, igual que grid computing y servicios web convergieron en WSRF. \\

Por último, a modo de curiosidad la principal diferencia entre un sistema grid y uno cloud reside en la virtualización, ya que en grid el usuario no comparte en tiempo real los recursos que tiene asignados, mientras que en cloud es indispensable la virtualización de recursos para conseguir dar servicio a más clientes y conseguir ese ahorro que prometen los proveedores.

\section{Web Services Resource Framework(WSRF)}

La arquitectura que presentan los servicios web ha sido ampliamente aceptada como medio para estructurar las interacciones existentes entre los servicios que forman parte de un sistema distribuido y que colaborar para conseguir un objetivo común. En la actualidad, los desarrolladores requieren a los entornos una mayor estandarización para facilitar interoperatividad adicional entre dichos servicios, pero hasta mediados de 2004 ningún grupo de investigación o grupo de expertos se había planteado seriamente la idea de proponer un estándar para modelar la comunicación entre servicios web que poseen recursos persistentes asociados. Así, en Enero de ese año, varios miembros de la organización \emph{Globus Alliance} y de la multinacional informática IBM definieron, con la ayuda de expertos de empresas como HP, SAP, Akamai, etc., la especificación de los documentos que deberían producirse en este modelo y la base de una arquitectura inicial. Estos documentos fueron enviados a la organización encargada de su estandarización, OASIS, en Marzo de 2004. En un principio, se formaron dos comités que se encargarían del estudio y desarrollo de ciertas partes de este nuevo estándar. Por un lado, estaba el \emph{WSRF Technical Committee} que gestionaba cuatro especificaciones: \emph{WS-ResourceProperties, WS-ResourceLifetime, WS-ServiceGroup, y WS-BaseFaults}. Por otro lado, el \emph{WSN Technical Committee} se encargaba de las especificaciones: \emph{WS-BaseNotification, WS-Topics, y WS-BrokeredNotification}. \\

WS-Resource Framework está inspirado en el trabajo realizado previamente por el \emph{Global Grid Forum's Open Grid Services Infrastructure (OGSI) Working Group} \cite{Foster03}. Más concretamente, puede ser visto como una sencilla refactorización de los conceptos e interfaces desarrollados en la especificación \emph{OGSI V1.0}, de manera que explota los recientes desarrollos en el área de los servicios web (por ejemplo, WS-Addressing). \\

El objetivo de este trabajo es introducir los conceptos fundamentales para la gestión y destrucción de servicios web persistentes, es decir, servicios web que llevan asociados recursos donde guardar los estados de los mismos, ya que hasta la aparición de esta aproximación, los servicios web eran considerados ``\emph{stateless}'' y, por tanto, no podían almacenar temporalmente datos o resultados de sus operaciones de una manera sencilla para el usuario, ya que era necesario almacenarlos en una base de datos ajena al servicio. En este enfoque, es necesario codificar la relación entre el servicio y el recurso en términos de patrones utilizando una serie de tecnologías ampliamente estudiadas, como, por ejemplo, el WS-Addressing y, también, será necesario hacer sus propiedades accesibles desde el exterior a través de un interfaz. En este sentido, llamaremos \emph{WS-Resource} a la asociación entre un servicio web y un recurso persistente.  


\subsection{Introducción}

WS-Resource Framework \cite{Ban06} es una especificación, desarrollada por OASIS y algunas de las empresas informáticas más pioneras, cuyo propósito es definir un marco genérico para el modelado y acceso a recursos asociados a servicios web, así como las relaciones entre dichos recursos en un entorno Grid/Cloud. Esta aproximación está compuesta por un conjunto de especificaciones que definen la representación del WS-Resource en los términos que especifican los mensajes intercambiados y los documentos XML relacionados. Asimismo, incluye mecanismos que describen el medio para consultar el estado de un recurso y la descripción del servicio, que forman conjuntamente la definición de un WS-Resource. Además, definen los pasos necesarios para hacer el estado de un servicio web accesible a través de su interfaz (descrita en WSDL).\\

Normalmente, las interfaces de los servicios web proporcionan al usuario la posibilidad de acceder y manipular el estado del mismo, como, por ejemplo, valores de datos que evolucionan por la interacción entre varios servicios. En otras palabras, los intercambios de mensajes que se implementan en el comportamiento de los servicios tienen como objetivo permitir el acceso a estos recursos persistentes. Sin embargo, la noción de recursos persistentes que subyace en la implementación de los servicios no es tan evidente en la definición de la interfaz \cite{Fost04}. Los mensajes que estos servicios envían y reciben implican (o animan al programador a inferir) la existencia de un tipo de recurso asociado. Por tanto, es deseable que se definan estándares que permitan el descubrimiento, creación, introspección, interacción y destrucción de dichos recursos y que la forma elegida para llevar a cabo esta misión sea lo más interoperable posible. Estas observaciones han motivado la aparición de la propuesta comentada anteriormente, WS-Resource, para modelar estados en el contexto de los servicios web. Un WS-Resource se define como la composición de un servicio web y sus recursos persistentes asociados, esto es, \emph{(i)} expresado como una asociación de un documento XML con un tipo definido con uno o varios \emph{portTypes} (un servicio podrá jugar un determinado rol si implementa todos los \emph{portTypes} que comprenden ese rol) y \emph{(ii)} direccionado y accedido de acuerdo al patrón del recurso implícito, una derivación de las \emph{Endpoint References} del WS-Addressing. Una \emph{Endpoint Reference} estará compuesta por: Uniform Resource Identifier (URI), parámetros del mensaje que se envió para solicitar el envío de la \emph{Endpoint Reference} y datos relativos a la interfaz que se usa. En este intercambio, el identificador del recurso persistente es encapsulado en una \emph{Endpoint Reference} y usado para identificar al recurso en cualquier intercambio de mensajes entre los servicios que formen la coreografía. Así, WSRF permite declarar, acceder, monitorizar y destruir WS-Resources mediante mecanismos convencionales, lo que facilita la tarea de gestión, ya que no es necesario hacer más difícil la lógica de decisión del servicio propietario del recurso para procesar los mensajes de gestión. Estos mecanismos convencionales componen cinco especificaciones técnicas que definen los medios por los cuales:

\begin{itemize}
\item Se destruye un WS-Resource, ya sea de manera síncrona con respecto a una petición explícita de destrucción o, a través de un mecanismo basado en tiempos (scheduled). Además, es posible declarar unas características específicas  de los recursos (WS-ResourceProperties) que podrían ser utilizadas para inspeccionar y monitorizar el tiempo de vida de dicho WS-Resource (WS-ResourceLifetime).
\item  Se definen los tipos de WS-Resource, que están compuestos por la interfaz de la descripción del servicio web (WSDL) y por un documento XML de propiedades del recurso. Por otro lado, el estado del WS-Resource puede ser consultado y modificado a través del intercambio de mensajes (WS-ResourceProperties)
\item Un Endpoint Reference (WS-Addressing) puede ser renovado cuando su información de direccionamiento ha caducado o ha dejado de ser válida por algún error (WS-RenewableReferences).
\item Además, se define la capacidad de implementar entornos heterogéneos como colecciones de servicios web, sean o no WS-Resources (WS-ServiceGroups).
\item La notificación de errores puede ser más estandarizada al usar tipos XML Schema para definir los fallos base y definir reglas que muestren cómo esos fallos son usados y extendidos (WS-BaseFaults).
\end{itemize}   

\subsection{WS-ResourceProperties}

Como se ha comentado anteriormente, WSRF utiliza una especificación concreta para definir las propiedades del WS-Resource. Este recurso estará compuesto por la definición de la interfaz en WSDL y un documento XML (Resource Properties Document) que especifica las propiedades del mismo, por ejemplo, el tamaño de disco, la capacidad del procesador, etc., de tal manera que si queremos acceder, modificar o actualizar este documento debemos utilizar una serie de mensajes preestablecidos en la especificación. Las operaciones que se pueden hacer son las siguientes:

\subsubsection{GetResourceProperty}
Esta operación como su propio nombre indica permite al servicio web que realiza la petición recuperar el valor de una {\bf única} propiedad del documento de propiedades. Para aclarar más los conceptos se define el siguiente ejemplo. \\


Dado el documento de propiedades:

\lstset{language=XML, numbersep=5pt,basicstyle=\small, frame=single}
\begin{lstlisting}
...
<GenericDiskDriveProperties 
xmlns: tns=``http://example.com/diskDrive'' >
  <tns:NumberOfBlocks>22</tns:NumberOfBlocks>
  <tns:BlockSize>1024</tns:BlockSize>
  <tns:Manufacturer>DrivesRUs</tns:Manufacturer>
</GenericDiskDriveProperties>
...
\end{lstlisting}

Una posible petición puede ser:

\lstset{language=XML, numbersep=5pt,basicstyle=\small, frame=single}
\begin{lstlisting}
...
<s12:Body>
  <wsrp:GetResourceProperty 
    xmlns:tns=``http://example.com/diskDrive''>
     tns:NumberOfBlocks
  </wsrp: GetResourceProperty>
</s12:Body>...
\end{lstlisting}

\subsubsection{GetMultipleResourceProperties}
Este método es equivalente al anterior, pero para acceder a más de una propiedad del documento en el mismo mensaje, es decir, se utiliza para evitar congestionar la red. El mensaje enviado sería:


\lstset{language=XML, numbersep=5pt,basicstyle=\footnotesize ,frame=single}
\begin{lstlisting}
...
<wsrp:GetMultipleResourceProperties
 xmlns:tns=``http://example.com/diskdrive''>
 <wsrp:ResourceProperty>tns:NumberOfBlock</wsrp:ResourceProperty>
 <wsrp:ResourceProperty>tns:BlockSize</wsrp:ResourceProperty>
</wsrp:GetMultipleResourceProperties>
...
\end{lstlisting}

\subsubsection{SetResourceProperties}
Este método se utiliza para realizar cambios en el documento de propiedades. Existen 3 tipos de cambios:

\begin{itemize}
\item Insert: Permite añadir nuevas propiedades en el documento.
\item Update: Se utiliza para actualizar el valor de alguna propiedad.
\item Delete: Elimina propiedades del documento.
\end{itemize}

Un posible ejemplo de petición sería:

\lstset{language=XML, numbersep=5pt, basicstyle=\small,frame=single}
\begin{lstlisting}
...
<s12:Body>
 <wsrpw:SetResourceProperties
        xmlns:tns=``http://example.com/diskdrive''>
   <wsrp:Update>
    <tns:NumberOfBlocks>143</tns:NumberOfBlocks>
   </wsrp:Update>

   <wsrp:Delete resourceProperty=``tns:Manufacturer''/>

   <wsrp:Insert>
    <tns:someElement>42</tns:someElement>
   </wsrp:Insert>

 </wsrp:SetResourceProperties>
</s12:Body>
...
\end{lstlisting}


El documento de propiedades quedaría con el siguiente formato:

\lstset{language=XML, numbersep=5pt, frame=single}
\begin{lstlisting}
...
<GenericDiskDriveProperties
  xmlns:tns=``http://example.com/diskDrive''>
  
  <tns:NumberOfBlocks>143</tns:NumberOfBlocks>
  <tns:BlockSize>1024</tns:BlockSize>
  <tns:someElement>42</tns:someElement>

</GenericDiskDriveProperties>
...
\end{lstlisting}

\subsubsection{QueryResourceProperties}
Como su propio nombre indica, este método se utiliza para realizar consultas sobre propiedades del recurso. Por ejemplo si queremos saber si el número de bloques es mayor que 20 y el tamaño de bloque es 1024 realizaríamos la siguiente consulta:

\lstset{language=XML, numbersep=5pt, frame=single}
\begin{lstlisting}
...
<s12:Body>
 <wsrp:QueryResourceProperties>
  <wsrp:QueryExpression
   Dialect=``http://www.w3.org/REC-xpath-19991116''>
    boolean(/*/NumberOfBlocks>20 and /*/BlockSize=1024)
  </wsrp:QueryExpression>
 </wsrp:QueryResourceProperties>
</s12:Body>
...
\end{lstlisting}

\newpage
La respuesta que envía el otro servicio es:


\lstset{language=XML, numbersep=5pt, frame=single}
\begin{lstlisting}
...
<s12:Body>
 <wsrp:QueryResourcePropertiesResponse>
   true
 </wsrp:QueryResourcePropertiesResponse>
</s12:Body>
...
\end{lstlisting}


\subsection{WS-Base Faults}
El diseñador de un servicio web normalmente utiliza interfaces definidas por otros, por lo que un método que estandarizase el formato de los mensajes de notificación de errores facilitaría la labor de los desarrollares. Éste es el objetivo de WS-BaseFaults. Los mensajes de fallos en WSRF tienen el siguiente formato:


\lstset{language=XML, numbersep=5pt, frame=single}
\begin{lstlisting}
...
<BaseFault> 
  <Timestamp>xsd:dateTime</Timestamp> 
  <OriginatorReference> 
    wsa:EndpointReferenceType 
  </OriginatorReference> ? 
  <ErrorCode dialect=``anyURI''>xsd:string</ErrorCode>? 
  <Description>xsd:string</Description> * 
  <FaultCause>wsbf:BaseFault</FaultCause> * 
</BaseFault>
...
\end{lstlisting}
donde:

\begin{itemize}
\item Timestamp: Hora exacta cuando el fallo ha ocurrido.
\item OriginatorReference: Dirección en formato WS-Addressing del servicio que ha generado el fallo.
\item ErrorCode: Código de error para ser utilizado por sistemas de información de fallos, por ejemplo, POSIX errno.
\item Description: Explicación de la causa del fallo (en lenguaje natural).
\item FaultCause: Causa técnica del fallo. 
\end{itemize}

\subsection{WS-ServiceGroup}
Esta especificación permite crear grupos que comparten una serie de propiedades en común, es decir, agrupar diferentes servicios web que tienen comportamientos similares.

\subsection{WS-ResourceLifetime}

El tiempo de vida de un WS-Resource se define como el período que transcurre entre su instanciación y su destrucción. La misión de esta especificación es estandarizar el proceso de destrucción de un recurso y definir mecanismos para monitorizar este ciclo de vida, pero lo que no se define es cómo crear el WS-Resource. Generalmente, en los sistemas distribuidos, los clientes sólo quieren tener un recurso por un determinado intervalo de tiempo, aunque en muchos escenarios es más apropiado para el cliente que se produzca la inmediata destrucción del recurso. Otro ejemplo claro de uso se presenta cuando el cliente quiere suscribirse a un servicio por un cierto tiempo y quiere que después de este tiempo se destruya dicha unión. Como se comentó en la introducción, existen dos formas de destruir un recurso: inmediata, mediante un mensaje explícito o temporizada, mediante un mensaje que activa o gestiona un timer. 

\subsubsection{Destrucción inmediata}
Para la destrucción inmediata sólo hace falta poner \emph{$<wsrl:Destroy/>$} dentro del cuerpo ($<Body>$) del mensaje SOAP que se envía al servicio que gestiona el recurso y dicho servicio responder con \emph{$<wsrl:DestroyResponse/>$} dentro del cuerpo (\emph{$<Body>$}) del mensaje SOAP de respuesta.

\subsubsection{Destrucción temporizada}

En este caso, el WS-Resource tiene asociado un tiempo de terminación que define el tiempo después del cual se espera que el recurso haya sido destruido y, razonablemente, se espera que antes del mismo el recurso esté disponible. A continuación se muestra un ejemplo de cómo determinar el tiempo de terminación de un recurso:

\lstset{language=XML, numbersep=5pt, frame=single}
\begin{lstlisting}
...
  <s12:Envelope
     <ex:ResourceDisambiguator>
      uuid:ba32-8680cace43f9
     </ex:ResourceDisambiguator>
     <s12:Body>
      <wsrl:SetTerminationTime>
       <wsrl:RequestedTerminationTime>
        2001-12-31T12:00:00
       </wsrl:RequestedTerminationTime>
     </wsrl:SetTerminationTime>
     </s12:Body>
  </s12:Envelope>
...
\end{lstlisting}



Como podemos observar el servicio que solicita la destrucción puede indicar la hora de destrucción y la hora actual (para evitar desajustes por la forma de representar la zona horaria). Una vez que CurrentTime alcanza el valor TerminationTime, el recurso se destruye sin ninguna intervención más y se notifica al emisor del mensaje de destrucción que el recurso deja de estar disponible. Existe otro mensaje que se manda desde el receptor al emisor para comunicarle que ha recibido la petición de cambio.  \\

Sin embargo, puede darse la situación de que haya más de un servicio utilizando el recurso que vaya a destruirse por lo que el propietario del recurso puede decidir o no (se deja a libre elección del programador) implementar los mensajes WS-Notification para informar a los interesados que el recurso deja de estar disponible. Para llevar a cabo esta tarea debe crear este Topic: 

\newpage

\lstset{language=XML, numbersep=5pt, frame=single}
\begin{lstlisting}
...
<wstop:TopicSpace name=``ResourceLifetime''
   targetNamespace=
   http://docs.oasis-open.org/wsrf/2004/06/
   wsrf-WS-ResourceLifetime-1.2-draft-01.xsd
 
 <wstop:Topic name=``ResourceTermination''>
   <wstop:MessagePattern>
     <wsrp:QueryExpression
       dialect= http://www.w3.org/REC-xpath-19991116 >
        boolean(/*/TerminationNotification)
     </wsrp:QueryExpression>
 </wstop:MessagePattern>
...
\end{lstlisting}



Además, el mensaje de notificación asociado debe contener los siguientes campos: 


\lstset{language=XML, numbersep=5pt, frame=single}
\begin{lstlisting}
...
<wsrl:TerminationNotification>
 <wsrl:TerminationTime>xsd:dateTime</wsrl:TerminationTime>
 <wsrl:TerminationReason>xsd:any</wsrl:TerminationReason>?
</wsrl:TerminationNotification>
...
\end{lstlisting}
 
donde \emph{TerminationTime} informa de la fecha de destrucción y \emph{TerminationReason} contiene la explicación de la destrucción.

\section{WS-Notification}

Esta especificación permite a un \emph{NotificationProducer} enviar un mensaje de notificación a un \emph{NotificationConsumer} de dos maneras diferentes:

\begin{enumerate}
\item El \emph{NotificationProducer} envía un mensaje de notificación al \emph{NotificationConsumer} sin seguir ningún formalismo.
\item El \emph{NotificationProducer} utiliza el formalismo que se describe a continuación para enviar las notificaciones. 
\end{enumerate} 

La opción a utilizar la elegirá el suscriptor cuando mande la petición de suscripción. En este sentido, la segunda opción permite al usuario recibir un amplio rango de mensajes de notificación, ya que la información que se envía en estos mensajes se obtiene de un árbol de Topics (temas) y, por tanto, se permite enviar subárboles en un mismo mensaje para informar de diferentes Topics. En la Figura \ref{12} vemos un ejemplo:


\begin{figure}[h!]
  \center
    \includegraphics[scale=0.45]{Figures/12}
     \caption{Ejemplo de uso de WS-Notification sin broker.}
  \label{12}
\end{figure}
 
Este caso muestra un ejemplo de interacción entre un consumidor y un productor de notificaciones, en el caso de que el suscriptor y el consumidor sean la misma entidad. El sistema es simple ya que tenemos un consumidor y un productor que publica 2 topics: SystemLoadHigh y SystemFault. Los pasos necesarios son: 

\begin{enumerate}
\item En primer lugar, el consumidor se suscribe al topic SystemLoadHigh, por lo que internamente se crea un \emph{Subscription resource} con la información de la suscripción. El productor debe implementar un método \emph{Subscribe} y el consumidor un método \emph{Notify}.  
\item Después, el productor debe enviar una notificación cuando el sistema sobrepase una determinada carga de trabajo. Por ejemplo, nuestro sistema enviará notificaciones cuando la carga de trabajo sea mayor de 50\%.
\item Por último, el productor envía la notificación invocando la operación \emph{Notify} en el consumidor.
\end{enumerate}
   
Un ejemplo de mensaje \emph{Notify} es:
 
\lstset{language=XML, numbersep=5pt, frame=single}
\begin{lstlisting}
...
<wsnt:Notify>
    <wsntw:NotificationMessage>
     <wsnt:Topic Dialect= xsd:anyURI >
       {any}
     </wsnt:Topic>
     <wsnt:ProducerReference>?
      wsa:EndpointReference
     </wsnt:ProducerReference>
     <wsnt:Message>xsd:any</wsnt:Message>
    <wsnt:NotificationMessage>+
</wsnt:Notify>
...
\end{lstlisting}

Como podemos observar el mensaje \emph{Notify} contiene uno o varios mensajes de notificación (\emph{NotificationMessages}). Los campos dentro de éstos son: 

\begin{itemize}
\item Topic: La información del topic que se envía.
\item Dialect: El dialecto usado para expresar el topic anterior, es decir, el lenguaje utilizado para expresarlo.
\item ProducerReference: Dirección del productor.
\item Message: Una copia de la carga útil (payload) del mensaje actual.
\end{itemize}

A continuación, se muestra el mensaje que manda el suscriptor para registrar su interés en uno o más topics:


\lstset{language=XML, numbersep=5pt, frame=single}
\begin{lstlisting}
...
<wsnt:Subscribe>
  <wsnt:ConsumerReference>
    wsa:endpointReference
  </wsnt: ConsumerReference>
  <wsnt:TopicExpression Dialect = xsd:anyURI >
    {any}
  </wsnt:TopicExpression>
  <wsnt:UseNotify>xsd:boolean</wsnt:UseNotify>?
  <wsnt:Precondition>wsrp:QueryExpression</Precondition>?
  <wsnt:Selector>wsrp:QueryExpression</wsnt:Selector>?
  <wsnt:SubscriptionPolicy>{any}</wsnt:SubscriptionPolicy>?
  <wsnt:InitialTerminationTime>
    xsd:dateTime
  </wsnt:InitialTerminationTime>?
</wsnt:Subscribe>

...
\end{lstlisting}


Los conceptos importantes en este mensaje son \emph{UseNotify} que se utiliza para decidir si el mensaje de notificación sigue el formalismo WS-Notification o se manda sin formato, \emph{Precondition} que es la condición que genera mensajes de notificación, es decir, si se cumple esta condición se generan mensajes, pero debe cumplirse también la condición \emph{selector} para enviarlos a los destinatarios que es la que se usa para decidir si se transmiten o no los mensajes generados. Además, \emph{SubscriptionPolicy} se podría utilizar para controlar el ratio de envío de mensajes(por ejemplo, no más de 3 por segundo) y \emph{InitialTerminationTime} contiene una sugerencia del tiempo de vida de la suscripción. WSRF también incluye mensajes para detener la suscripción, reanudarla o para que un servicio que acaba de unirse a una suscripción pueda obtener un historial de notificaciones sobre un determinado topic.



\subsection{WS-BrokeredNotification}

Un \emph{NotificationBroker} es un intermediario que, entre otras cosas, permite el envío de mensajes entre uno o varios \emph{Publishers} y uno o varios \emph{NotificationConsumers}. La misión del \emph{Publisher} es observar ciertas situaciones y crear mensajes de notificación para informar de esas situaciones, mientras que el broker es el encargado de distribuir estos mensajes. \\

En este caso, se pueden dar tres relaciones entre las partes: \emph{simple publishing}, \emph{composable publishing} y \emph{demand-based publishing}. En el primer caso, el \emph{Publisher} es el encargado de observar las situaciones y notificarlas al broker que será el encargado de transmitirlas a los interesados. En el segundo caso, el papel del \emph{Publisher} lo realizará una entidad que implementa una serie de servicios especificados en WS-Notification (NotificationProducer). En este caso, el mensaje de notificación puede llegar a otros consumidores que estuviesen suscritos al productor. En ambos casos, el broker puede pedir al \emph{Publisher} que se registre para poder publicar mensajes sobre un topic determinado. El último enfoque (\emph{demand-based publishing}) requiere que el \emph{Publisher} sea un \emph{NotificationProducer} y, así, acepte mensajes de suscripción. El objetivo es reducir el número de mensajes de notificación haciendo que éstos solo se manden cuando se soliciten expresamente.


This chapter is about the state of the art of Service-Oriented Computing, the use of formalisms for the analysis of Web Service compositions, and the specification of electronic contracts (e-contract). We specially focus on the application of e-contracts to Web Service compositions, describing some of the existing approaches for that purpose. We also review the related work in the field of formal specification and verification of e-contracts.

%%%Service-Oriented Computing%%%
\section{Service-Oriented Computing (SOC)}\label{SOC}
\markright{~\ref{SOC} Service-Oriented Computing (SOC)}

The Service-Oriented Computing (SOC) paradigm promotes the use of services for the development of massively distributed applications, trying to achieve the creation of fast, low-cost, flexible and scalable applications \cite{Papazoglou2007}. Services are the main building block of this paradigm, being these services self-describing and platform-independent. Thanks to the use of standards for description, publication, discovery and invocation, the services can be integrated without taking care of the low-level implementation details of each service. The aim of SOC is to make it possible the creation of dynamic business processes and agile applications by providing an easy way to assemble application components into a loosely coupled network of services.

\subsection{Service-Oriented Architecture (SOA)}\label{SOA}

To reach the goals of SOC, a Service-Oriented Architecture (SOA) is defined. SOA is a software architecture based on the utilization of services, being these services provided to the user of the application or to other services in the network. This is possible by the use of service interfaces that can be published and discovered.

SOA is based on a model of roles where every service can play multiple roles. For example, a service can offer a certain functionality to a user and, at the same time, being the consumer of the functionality provided by some other services. Such model reduces the complexity of applications and increases their flexibility.

Although at the beginning of SOA there were several architectures aspiring to become SOA standards \cite{Karp2000,Sun1999}, the most successful one was the architecture based on Web Services.

\subsection{Web Services (WS)}\label{WS}

W3C defines a Web Service (WS) in the following way \cite{W3C2004}:

\begin{quotation}
	``A Web Service is a software system designed to support interoperable machine-to-machine interaction over a network. It has
an interface described in a machine-processable format (specifically WSDL). Other systems interact with the Web Service in a manner prescribed by its description using SOAP-messages, typically conveyed using HTTP with an XML serialization in conjunction with other Web-related standards.''
\end{quotation}

We can see in this definition that there are two basic standards related to Web Services: Web Service Description Language (WSDL) for the definition of the service functionality and its properties \cite{W3C2001}, and Simple Object Access Protocol (SOAP) for the exchange of XML messages between services \cite{W3C2007}. There is also an additional standard called Universal Description, Discovery and Integration (UDDI) used to create Web Service directories and to search for services in the network \cite{OASIS2004}. The use of these standard protocols is the key point to improve the integration between different parties in a Web Service architecture.

In Figure \ref{Figure1} a possible representation of the Web Service architecture stack is shown. We can see that the three standards described above are only a small part of the stack. We also need protocols to define security aspects (ensuring that exchanges of information are not modified or forged in a verifiable manner and that parties can be authenticated), to provide reliable messaging for the exchange of information between parties, to specify the collaboration between services when we compose them, to individually describe the behaviour of each service in a business process, etc. The problem is that whereas the standards for basic services (WSDL and SOAP) are widely adopted for their respective purposes, the situation is not so clear when we talk about composing services, having multiple protocols aspiring to become a standard in this layer.

\begin{figure}[h]
\begin{center}
\psfig{file=Figures/ws-stack.eps,scale=.55}
\end{center}
\caption{Web Service architecture stack.}
\label{Figure1}
\end{figure}

\subsection{Web Service Composition}\label{WSC}

Two different approaches can be followed when we talk about composing Web Services. They are called \textit{orchestration} and \textit{choreography}. The former describes the individual business process followed by each one of the participants in the composition, while the latter describes the composition from a global viewpoint, defining the interactions (exchange of messages) happening between the parties, that is, how they collaborate in the composition. However, the ideal solution would be fusing both approaches in a single language and environment \cite{Papazoglou2007}.

Anyway, the languages we can use in both cases should accomplish some common goals: (i) the capacity of modelling service interactions, including control flow and data constraints, (ii) the possibility of specifying exceptional behaviour, indicating which errors can happen in the execution of the composition and the way of handling these errors, and (iii) the ability to model Web Service compositions at a high level, without taking care of the implementation details of each one of the services.

\textbf{\subsubsection{Business Process Execution Language (BPEL)}}

Considering the orchestration approach, one of the most used languages for this purpose is Business Process Execution Language (BPEL), also known as BPEL4WS or WSBPEL \cite{OASIS2007}. A BPEL specification models the behaviour of the different services taking part in a business process, defining a BPEL source file for each service. BPEL provides an XML syntax to describe the control logic necessary to coordinate all the services participating in the process. An orchestration engine is responsible for the execution of the processes, coordinating all the activities and compensating any error that could happen. BPEL can be seen as a layer over WSDL, providing this latter language the available functionality while BPEL defines how to sequence the operations \cite{Peltz2003}.

The components of a BPEL specification are the following:

\begin{itemize}

\item \textbf{Events}, which describe the flow execution in an event-driven way.

\item \textbf{Variables},  which are defined by using  WSDL schemes for internal or external purposes, and are used in the message flow.

\item \textbf{Correlations}, which identify the processes interacting by means of messages.

\item \textbf{Fault handling}, defining the behaviour when an exception is thrown.

\item \textbf{Event handling}, defining the behaviour when an event happens.

\item \textbf{Activities}, which are the basic unit of behaviour of a Web Service.

\end{itemize}

For example, in figure \ref{Example1} we can see part of a BPEL specification corresponding to shipping service.

\begin{figure}
\begin{center}
\begin{tabular}{|p{11cm}|}
\hline
\begin{verbatim}

<process name="shippingService"
...
   <sequence>   
      ...
      <if>
         <condition>
            bpel:getVariableProperty('shipRequest',
            	'props:shipComplete')
         </condition>         
         <sequence>
            ...
            <invoke partnerLink="customer"
               operation="shippingNotice"
               inputVariable="shipNotice">
               <correlations>
                  <correlation set="shipOrder" 
                  	pattern="request" />
               </correlations>
            </invoke>
         </sequence>
         <else>
            <sequence>
              ...
              <while>
                <condition>
                  $itemsShipped
                  &lt;
                  bpel:getVariableProperty(
                  'shipRequest','props:itemsTotal')
                </condition>
                <sequence>
                  ...
                  <invoke partnerLink="customer"
                    operation="shippingNotice"
                    inputVariable="shipNotice">
                    <correlations>
                       <correlation set="shipOrder"
                          pattern="request" />
                    </correlations>
                 </invoke>
                 ...
                </sequence>
              </while>
            </sequence>
         </else>
      </if>
   </sequence>
</process>
\end{verbatim}\\
\hline
\end{tabular}
\caption{Part of a shipping service specification in BPEL} \label{Example1}
\end{center}
\end{figure}




%%%Formal Analysis of Web Service Compositions%%%
\section{Formal Analysis of Web Service Compositions}\label{AnalysisWSC}

In last years the formal analysis of Web Service compositions has been recognized as an important problem that needs to be solved \cite{Carbone2006,Dong2006,Foster2007,Yang2008}. A strict analysis is necessary to guarantee the correct composition of the services for multiple reasons: the integration of several independent applications, the possibility of having incomplete specifications of some services, the impossibility of using traditional evaluation techniques such as software testing, \ldots

The analysis of Web Service compositions usually consists of checking its specification correctness by analysing if a set of functional and non-functional requirements are fulfilled. The behavioural requirements are especially interesting, as they specify the properties required to reach a concrete business goal. These requirements can include general properties such as deadlock freeness or correct termination, but they can also be defined explicitly, for example defining the conformance to a concrete model. This formal analysis is usually done by means of formal methods.

Formal methods \cite{Wing1990} are a collection of notations and techniques for describing and analyzing systems \cite{Peled2001}. They are called \textit{formal} because they are based on mathematical theories (logics, automata, sets, \ldots). In formal methods we can distinguish between the \textit{formal specification}, which describes unambiguously a system or its properties, and the \textit{formal analysis} or \textit{formal verification}, which serves to verify if a system satisfies its specification.

Formal methods usually cannot guarantee the correctness of the implementation and, if the specification is not correct, the verification results will also be wrong. Despite these and some other limitations, formal methods are still needed because they increase the confidence on system reliability, minimize the number of errors in the implementation and can find out errors impossible to find with other techniques such as testing.

When we are going to apply a formal method it is very important to choose the right level of abstraction in the specification of the system depending on what we want to analyze or verify. An underspecification can lead to wrong verification results because the specification is incomplete, whereas an overspecification can lead to the \textit{state explosion problem}, making the intended analysis of the system infeasible.

Formal methods can be applied in different stages of the computer system development process, providing different information about the system in each one of these stages. The application of these methods is usually complex, being impossible without some kind of tool support. For this purpose, the language syntax of the specification must be explicit and the language semantics of the specification must be restricted. In this way, formal specifications are amenable to automate analysis and verification.

The choice of using one formal method or another depends on many factors: the problem we want to solve, the type of system, the properties we want to check, and so on. In the case of complex systems, such as distributed concurrent systems, it is needed a combination of several techniques for the analysis.



\subsection{Specification Formalisms}\label{Formalisms}





\section{Summary}\label{sumArt}
\markright{~\ref{sumArt} Summary}

This chapter has described the state of the art of Service-Oriented Computing (SOC), the formalization of Web Service compositions, and the specification of electronic contracts (e-contracts).

The development of systems based on Web Services allows the creation of fast, low-cost, flexible and scalable applications, where the integration is possible thanks to the definition of multiple standard protocols (WSDL, SOAP, UDDI). However, the correct composition of Web Services is still an open problem, where different approaches can be followed, such as orchestration (BPEL) and choreography (WS-CDL, WSCI, OWL-S). The formal analysis of Web Service compositions by means of formal methods is therefore necessary to guarantee the correct composition.

Several formal techniques can be used for the analysis of Web Service compositions, being model checking one of the most popular. This is an automated technique consisting of the construction of a finite-state model of the system to check if
some properties are satisfied. Different specification formalisms can be used in model checking (process algebras, Petri nets, automata) and there are several tools supporting each one of these formalisms (CWB-NC, CPN Tools, UPPAAL).


